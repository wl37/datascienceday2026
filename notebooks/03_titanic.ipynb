{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "83153e6d",
      "metadata": {},
      "source": [
        "# ðŸš¢ Titanic Survival Analysis\n",
        "## *Can a machine predict who survives?*\n",
        "\n",
        "---\n",
        "\n",
        "On April 15, 1912, the RMS Titanic sank after hitting an iceberg.  \n",
        "**1,502 of 2,224 passengers died.**\n",
        "\n",
        "We have data on each passenger: their age, class, sex, fare paid, and whether they survived.\n",
        "\n",
        "**Two questions we'll answer today:**\n",
        "1. Which groups of people had the best (and worst) survival rates? â†’ *Data Exploration*\n",
        "2. Can we build a program that predicts survival from passenger info? â†’ *Machine Learning*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2317171",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ipywidgets as widgets\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\", font_scale=1.15)\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"../data/titanic.csv\")\n",
        "print(f\"Loaded {len(df)} passengers, {df['survived'].sum()} survived ({df['survived'].mean()*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d75d154c",
      "metadata": {},
      "source": [
        "## Part 1 â€” Explore the Data\n",
        "\n",
        "Let's look at who was on board and filter by different characteristics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88b5fe2b",
      "metadata": {},
      "outputs": [],
      "source": [
        "@widgets.interact(\n",
        "    sex=widgets.ToggleButtons(options=[\"All\", \"Male\", \"Female\"], description=\"Sex:\", button_style=\"\"),\n",
        "    pclass=widgets.ToggleButtons(options=[\"All Classes\", \"1st Class\", \"2nd Class\", \"3rd Class\"], description=\"Class:\", button_style=\"\"),\n",
        ")\n",
        "def explore(sex, pclass):\n",
        "    filtered = df.copy()\n",
        "    if sex != \"All\":\n",
        "        filtered = filtered[filtered[\"sex\"] == sex.lower()]\n",
        "    if pclass != \"All Classes\":\n",
        "        cls_map = {\"1st Class\": 1, \"2nd Class\": 2, \"3rd Class\": 3}\n",
        "        filtered = filtered[filtered[\"pclass\"] == cls_map[pclass]]\n",
        "\n",
        "    if len(filtered) == 0:\n",
        "        print(\"No passengers match the selected filters.\")\n",
        "        return\n",
        "\n",
        "    survived    = filtered[\"survived\"].sum()\n",
        "    total       = len(filtered)\n",
        "    surv_rate   = survived / total * 100\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(14, 5))\n",
        "\n",
        "    counts = filtered[\"survived\"].value_counts().rename({0: \"Did Not Survive\", 1: \"Survived\"})\n",
        "    axes[0].pie(counts, labels=counts.index, autopct=\"%1.1f%%\",\n",
        "                colors=[\"#E8575A\", \"#5B8FB9\"], startangle=90,\n",
        "                wedgeprops={\"edgecolor\": \"white\", \"linewidth\": 2})\n",
        "    axes[0].set_title(f\"Survival Rate\\n{survived}/{total} ({surv_rate:.0f}%)\", weight=\"bold\")\n",
        "\n",
        "    age_data = filtered.dropna(subset=[\"age\"])\n",
        "    for val, label, color in [(1, \"Survived\", \"#5B8FB9\"), (0, \"Did Not Survive\", \"#E8575A\")]:\n",
        "        axes[1].hist(age_data[age_data[\"survived\"] == val][\"age\"],\n",
        "                     bins=20, alpha=0.6, label=label, color=color)\n",
        "    axes[1].set_xlabel(\"Age\")\n",
        "    axes[1].set_ylabel(\"Count\")\n",
        "    axes[1].set_title(\"Age Distribution\", weight=\"bold\")\n",
        "    axes[1].legend()\n",
        "\n",
        "    surv_by_class = filtered.groupby(\"class\")[\"survived\"].mean() * 100\n",
        "    surv_by_class = surv_by_class.reindex([\"First\", \"Second\", \"Third\"]).dropna()\n",
        "    axes[2].bar(surv_by_class.index, surv_by_class.values,\n",
        "                color=[\"#F4A261\", \"#5B8FB9\", \"#6BCB77\"], edgecolor=\"white\", linewidth=1.5)\n",
        "    axes[2].set_ylabel(\"Survival Rate (%)\")\n",
        "    axes[2].set_title(\"Survival Rate by Class\", weight=\"bold\")\n",
        "    axes[2].set_ylim(0, 100)\n",
        "    for i, v in enumerate(surv_by_class.values):\n",
        "        axes[2].text(i, v + 2, f\"{v:.0f}%\", ha=\"center\", fontweight=\"bold\")\n",
        "\n",
        "    plt.suptitle(f\"Titanic â€” {sex} Â· {pclass} Â· {total} passengers\",\n",
        "                 fontsize=13, weight=\"bold\", y=1.02)\n",
        "    sns.despine()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2769b26",
      "metadata": {},
      "source": [
        "## Part 2 â€” Machine Learning: Decision Tree\n",
        "\n",
        "A **decision tree** is a machine learning model that learns rules like:\n",
        "\n",
        "```\n",
        "IF sex = female\n",
        "   AND class = 1st or 2nd  â†’  likely SURVIVED\n",
        "IF sex = male\n",
        "   AND age > 15            â†’  likely DID NOT SURVIVE\n",
        "```\n",
        "\n",
        "We'll:\n",
        "1. Split data into **training** (80%) and **test** (20%) sets\n",
        "2. Train the tree on the training data\n",
        "3. Test how accurate it is on data it's *never seen before*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15f01fcc",
      "metadata": {},
      "outputs": [],
      "source": [
        "features_df = df[[\"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\"]].copy()\n",
        "features_df[\"sex\"] = (features_df[\"sex\"] == \"female\").astype(int)\n",
        "features_df = features_df.fillna(features_df.median(numeric_only=True))\n",
        "target = df[\"survived\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features_df, target, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "feature_names = [\"Ticket Class\", \"Female?\", \"Age\", \"Siblings/Spouse\", \"Parents/Children\", \"Fare\"]\n",
        "class_names   = [\"Did Not Survive\", \"Survived\"]\n",
        "\n",
        "@widgets.interact(depth=widgets.IntSlider(\n",
        "    value=3, min=1, max=6, step=1,\n",
        "    description=\"Tree depth:\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        "    layout=widgets.Layout(width=\"400px\"),\n",
        "))\n",
        "def train_and_show(depth):\n",
        "    clf = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
        "    clf.fit(X_train, y_train)\n",
        "    preds    = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, preds)\n",
        "    cm       = confusion_matrix(y_test, preds)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, max(4, depth * 1.8)))\n",
        "\n",
        "    plot_tree(clf, feature_names=feature_names, class_names=class_names,\n",
        "              filled=True, rounded=True, fontsize=9, ax=axes[0])\n",
        "    axes[0].set_title(f\"Decision Tree (depth = {depth})\", weight=\"bold\", fontsize=13)\n",
        "\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[1],\n",
        "                xticklabels=class_names, yticklabels=class_names,\n",
        "                linewidths=1, linecolor=\"white\")\n",
        "    axes[1].set_xlabel(\"Predicted\", fontsize=11)\n",
        "    axes[1].set_ylabel(\"Actual\", fontsize=11)\n",
        "    axes[1].set_title(f\"Confusion Matrix â€” Accuracy: {accuracy*100:.1f}%\",\n",
        "                      weight=\"bold\", fontsize=13)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nModel accuracy on unseen test data: {accuracy*100:.1f}%\")\n",
        "    print(f\"Training set: {len(X_train)} passengers | Test set: {len(X_test)} passengers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f699efc",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "1. **Data tells stories.** The Titanic data shows stark differences: women and 1st-class passengers had far higher survival rates.\n",
        "2. **Machine learning learns patterns from examples.** The decision tree found these rules automatically â€” we never told it \"women first\".\n",
        "3. **Deeper trees = more complex rules.** But too deep and the model *memorizes* the training data instead of learning general patterns. This is called **overfitting**.\n",
        "4. **The confusion matrix** shows exactly where the model makes mistakes â€” predicting no survival when there was, and vice versa.\n",
        "\n",
        "---\n",
        "*This dataset is also used in real ML courses at top universities â€” you've just done what data science students do!*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}